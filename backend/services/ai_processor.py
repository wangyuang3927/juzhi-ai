"""
FocusAI AI Processor
Uses DeepSeek via SiliconFlow to generate insight cards from raw news.
"""
import json
import uuid
from typing import Optional
from datetime import datetime
from openai import OpenAI

from config import get_settings, PROFESSIONS
from models import InsightCard, RawNews, Profession


class TavilyKeyRotator:
    """
    Tavily API Key è½®è¯¢å™¨
    è‡ªåŠ¨åœ¨å¤šä¸ª key ä¹‹é—´è½®è¯¢ï¼Œå®ç°å…è´¹é¢åº¦å åŠ 
    """
    def __init__(self, keys: list):
        self.keys = keys
        self.current_index = 0
        self._lock = None  # å»¶è¿Ÿåˆå§‹åŒ–
    
    def get_next_key(self) -> str:
        """è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ API Key"""
        if not self.keys:
            return ""
        key = self.keys[self.current_index]
        self.current_index = (self.current_index + 1) % len(self.keys)
        return key
    
    def has_keys(self) -> bool:
        return len(self.keys) > 0
    
    def key_count(self) -> int:
        return len(self.keys)


class AIProcessor:
    """
    AI processor that transforms raw news into insight cards.
    Uses DeepSeek model via SiliconFlow API (OpenAI-compatible).
    """
    
    def __init__(self):
        settings = get_settings()
        self.client = OpenAI(
            api_key=settings.siliconflow_api_key,
            base_url=settings.siliconflow_base_url
        )
        self.model = settings.deepseek_model
        
        # åˆå§‹åŒ– Tavily Key è½®è¯¢å™¨
        tavily_keys = settings.get_tavily_keys()
        self.tavily_rotator = TavilyKeyRotator(tavily_keys)
        if tavily_keys:
            print(f"âœ… Tavily å·²é…ç½® {len(tavily_keys)} ä¸ª API Keyï¼ˆè½®è¯¢æ¨¡å¼ï¼‰")
        else:
            print("âš ï¸ æœªé…ç½® Tavily API Keyï¼Œæœç´¢åŠŸèƒ½å°†ä½¿ç”¨é™çº§æ•°æ®")
    
    def _get_profession_display(self, profession: Profession) -> str:
        """Get Chinese display name for profession."""
        return PROFESSIONS.get(profession.value, "èŒåœºäººå£«")
    
    async def generate_insight(
        self, 
        news: RawNews, 
        profession: Profession
    ) -> Optional[InsightCard]:
        """
        Generate an insight card from raw news for a specific profession.
        
        Args:
            news: Raw news item
            profession: Target user profession
            
        Returns:
            InsightCard or None if generation fails
        """
        profession_name = self._get_profession_display(profession)
        
        system_prompt = """ä½ æ˜¯ FocusAI çš„ AI åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºèŒåœºäººå£«è§£è¯» AI è¡Œä¸šåŠ¨æ€ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€æ¡ AI æ–°é—»è½¬åŒ–ä¸ºå¯¹ç‰¹å®šèŒä¸šæœ‰ä»·å€¼çš„æ´å¯Ÿå¡ç‰‡ã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. summary (æ–°é—»æ‘˜è¦): 2-3 å¥è¯æ¦‚æ‹¬æ–°é—»æ ¸å¿ƒäº‹å®ï¼Œç®€æ´å®¢è§‚
2. impact (èŒä¸šå½±å“): é’ˆå¯¹ç”¨æˆ·èŒä¸šï¼Œåˆ†æè¿™æ¡æ–°é—»å¯¹ä»–/å¥¹çš„å·¥ä½œæ„å‘³ç€ä»€ä¹ˆï¼Œæä¾›å¯æ“ä½œçš„å»ºè®®ï¼Œè¯­æ°”äº²åˆ‡å®ç”¨
3. prompt (å¯å¤åˆ¶èµ„æº): æä¾›ä¸€ä¸ªç”¨æˆ·å¯ä»¥ç›´æ¥å¤åˆ¶ä½¿ç”¨çš„ Prompt æˆ–æŒ‡ä»¤ï¼Œä¸æ–°é—»å†…å®¹ç›¸å…³
4. tags (æ ‡ç­¾): 3-5 ä¸ªç›¸å…³æ ‡ç­¾ï¼Œæ ¼å¼ä¸º #æ ‡ç­¾å

è¯·ç”¨ JSON æ ¼å¼è¾“å‡ºï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{
    "summary": "æ–°é—»æ‘˜è¦",
    "impact": "å¯¹è¯¥èŒä¸šçš„å½±å“å’Œå»ºè®®",
    "prompt": "å¯å¤åˆ¶çš„ Prompt æˆ–æŒ‡ä»¤",
    "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2", "#æ ‡ç­¾3"]
}

æ³¨æ„ï¼š
- impact è¦é’ˆå¯¹ç”¨æˆ·èŒä¸šå®šåˆ¶ï¼Œä¸è¦æ³›æ³›è€Œè°ˆ
- prompt è¦å®ç”¨ï¼Œç”¨æˆ·å¤åˆ¶åå¯ä»¥ç›´æ¥ä½¿ç”¨
- è¯­è¨€ç®€æ´æœ‰åŠ›ï¼Œä¸è¦å•°å—¦"""

        user_prompt = f"""è¯·ä¸ºã€{profession_name}ã€‘è§£è¯»ä»¥ä¸‹ AI æ–°é—»ï¼š

æ ‡é¢˜ï¼š{news.title}

å†…å®¹ï¼š
{news.content[:2000]}  # é™åˆ¶å†…å®¹é•¿åº¦é¿å…è¶…å‡º token é™åˆ¶

æ¥æºï¼š{news.source_name}
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1000,
                response_format={"type": "json_object"}
            )
            
            result_text = response.choices[0].message.content
            result = json.loads(result_text)
            
            # Parse the published date
            timestamp = news.published_at.strftime("%Y-%m-%d") if news.published_at else datetime.now().strftime("%Y-%m-%d")
            
            return InsightCard(
                id=str(uuid.uuid4()),
                title=news.title,
                tags=result.get("tags", ["#AI"]),
                summary=result.get("summary", ""),
                impact=result.get("impact", ""),
                prompt=result.get("prompt", ""),
                url=news.source_url,
                timestamp=timestamp
            )
            
        except json.JSONDecodeError as e:
            print(f"JSON parse error: {e}")
            print(f"Raw response: {result_text}")
            return None
        except Exception as e:
            print(f"AI processing error: {e}")
            return None
    
    async def generate_general_insight(self, news: RawNews) -> Optional[InsightCard]:
        """
        Generate a general insight card (not profession-specific).
        Useful for initial processing before user selects profession.
        """
        system_prompt = """ä½ æ˜¯ FocusAI çš„ AI åŠ©æ‰‹ï¼Œä¸“é—¨è§£è¯» AI è¡Œä¸šåŠ¨æ€ã€‚
ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€æ¡ AI æ–°é—»è½¬åŒ–ä¸ºé€šç”¨çš„æ´å¯Ÿå¡ç‰‡ã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. summary (æ–°é—»æ‘˜è¦): 2-3 å¥è¯æ¦‚æ‹¬æ–°é—»æ ¸å¿ƒäº‹å®
2. impact (é€šç”¨å½±å“): åˆ†æè¿™æ¡æ–°é—»å¯¹èŒåœºäººå£«çš„æ™®éæ„ä¹‰
3. prompt (å¯å¤åˆ¶èµ„æº): æä¾›ä¸€ä¸ªç›¸å…³çš„å®ç”¨ Prompt
4. tags (æ ‡ç­¾): 3-5 ä¸ªç›¸å…³æ ‡ç­¾

è¯·ç”¨ JSON æ ¼å¼è¾“å‡ºï¼š
{
    "summary": "æ–°é—»æ‘˜è¦",
    "impact": "é€šç”¨å½±å“åˆ†æ",
    "prompt": "å¯å¤åˆ¶çš„ Prompt",
    "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2", "#æ ‡ç­¾3"]
}"""

        user_prompt = f"""è¯·è§£è¯»ä»¥ä¸‹ AI æ–°é—»ï¼š

æ ‡é¢˜ï¼š{news.title}

å†…å®¹ï¼š
{news.content[:2000]}

æ¥æºï¼š{news.source_name}
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1000,
                response_format={"type": "json_object"}
            )
            
            result_text = response.choices[0].message.content
            result = json.loads(result_text)
            
            timestamp = news.published_at.strftime("%Y-%m-%d") if news.published_at else datetime.now().strftime("%Y-%m-%d")
            
            return InsightCard(
                id=str(uuid.uuid4()),
                title=news.title,
                tags=result.get("tags", ["#AI"]),
                summary=result.get("summary", ""),
                impact=result.get("impact", ""),
                prompt=result.get("prompt", ""),
                url=news.source_url,
                timestamp=timestamp
            )
            
        except Exception as e:
            print(f"AI processing error: {e}")
            return None

    async def generate_personalized_insight(
        self, 
        news: RawNews, 
        user_profile: dict
    ) -> Optional[InsightCard]:
        """
        Generate a personalized insight card based on user profile.
        Uses user's profession, interests, pain points, and goals.
        
        Args:
            news: Raw news item
            user_profile: User profile dict with interests, pain_points, goals, etc.
            
        Returns:
            InsightCard or None if generation fails
        """
        profession = user_profile.get("profession", "èŒåœºäººå£«")
        interests = user_profile.get("interests", [])
        pain_points = user_profile.get("pain_points", [])
        goals = user_profile.get("goals", [])
        skill_level = user_profile.get("skill_level", "")
        
        # æ„å»ºç”¨æˆ·ç”»åƒæè¿°
        profile_desc = f"èŒä¸šï¼š{profession}"
        if interests:
            profile_desc += f"\nå…³æ³¨é¢†åŸŸï¼š{', '.join(interests)}"
        if pain_points:
            profile_desc += f"\nå·¥ä½œç—›ç‚¹ï¼š{', '.join(pain_points)}"
        if goals:
            profile_desc += f"\nç›®æ ‡ï¼š{', '.join(goals)}"
        if skill_level:
            profile_desc += f"\nAI æŠ€èƒ½æ°´å¹³ï¼š{skill_level}"
        
        system_prompt = f"""ä½ æ˜¯ FocusAI çš„ AI åŠ©æ‰‹ï¼Œä¸“é—¨ä¸ºç”¨æˆ·æä¾›ä¸ªæ€§åŒ–çš„ AI èµ„è®¯è§£è¯»ã€‚

ç”¨æˆ·ç”»åƒï¼š
{profile_desc}

ä½ çš„ä»»åŠ¡æ˜¯å°†ä¸€æ¡ AI æ–°é—»è½¬åŒ–ä¸ºå¯¹è¿™ä½ç”¨æˆ·æœ€æœ‰ä»·å€¼çš„æ´å¯Ÿå¡ç‰‡ã€‚

è¾“å‡ºè¦æ±‚ï¼š
1. summary (æ–°é—»æ‘˜è¦): 2-3 å¥è¯æ¦‚æ‹¬æ–°é—»æ ¸å¿ƒäº‹å®
2. impact (ä¸ªæ€§åŒ–å½±å“): 
   - ç»“åˆç”¨æˆ·çš„èŒä¸šèƒŒæ™¯åˆ†æè¿™æ¡æ–°é—»å¯¹ä»–/å¥¹çš„æ„ä¹‰
   - é’ˆå¯¹ç”¨æˆ·çš„ç—›ç‚¹ï¼Œè¯´æ˜è¿™æ¡æ–°é—»å¦‚ä½•å¸®åŠ©è§£å†³é—®é¢˜
   - ç»“åˆç”¨æˆ·çš„ç›®æ ‡ï¼Œç»™å‡ºå¯æ“ä½œçš„è¡ŒåŠ¨å»ºè®®
   - æ ¹æ®ç”¨æˆ·çš„æŠ€èƒ½æ°´å¹³ï¼Œè°ƒæ•´å»ºè®®çš„å¤æ‚åº¦
3. prompt (å¯å¤åˆ¶èµ„æº): æä¾›ä¸€ä¸ªç”¨æˆ·å¯ä»¥ç›´æ¥ä½¿ç”¨çš„ Promptï¼Œæœ€å¥½èƒ½è§£å†³ç”¨æˆ·çš„æŸä¸ªç—›ç‚¹
4. tags (æ ‡ç­¾): 3-5 ä¸ªç›¸å…³æ ‡ç­¾

è¯·ç”¨ JSON æ ¼å¼è¾“å‡ºï¼š
{{
    "summary": "æ–°é—»æ‘˜è¦",
    "impact": "ä¸ªæ€§åŒ–å½±å“åˆ†æå’Œå»ºè®®",
    "prompt": "é’ˆå¯¹ç”¨æˆ·å®šåˆ¶çš„å¯å¤åˆ¶ Prompt",
    "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2", "#æ ‡ç­¾3"]
}}

æ³¨æ„ï¼š
- impact å¿…é¡»ç´§å¯†ç»“åˆç”¨æˆ·ç”»åƒï¼Œä½“ç°ä¸ªæ€§åŒ–
- prompt è¦é’ˆå¯¹ç”¨æˆ·çš„å…·ä½“åœºæ™¯è®¾è®¡
- è¯­æ°”äº²åˆ‡ä¸“ä¸šï¼Œåƒä¸€ä½æ‡‚ä½ çš„ AI é¡¾é—®"""

        user_prompt = f"""è¯·ä¸ºè¿™ä½ç”¨æˆ·è§£è¯»ä»¥ä¸‹ AI æ–°é—»ï¼š

æ ‡é¢˜ï¼š{news.title}

å†…å®¹ï¼š
{news.content[:2000]}

æ¥æºï¼š{news.source_name}
"""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.7,
                max_tokens=1200,
                response_format={"type": "json_object"}
            )
            
            result_text = response.choices[0].message.content
            result = json.loads(result_text)
            
            timestamp = news.published_at.strftime("%Y-%m-%d") if news.published_at else datetime.now().strftime("%Y-%m-%d")
            
            return InsightCard(
                id=str(uuid.uuid4()),
                title=news.title,
                tags=result.get("tags", ["#AI"]),
                summary=result.get("summary", ""),
                impact=result.get("impact", ""),
                prompt=result.get("prompt", ""),
                url=news.source_url,
                timestamp=timestamp
            )
            
        except Exception as e:
            print(f"AI personalized processing error: {e}")
            return None

    async def search_and_recommend_tools(self, profession: str, refresh_seed: int = 0, result_count: int = 6) -> list:
        """
        ä½¿ç”¨ Tavily æœç´¢çœŸå® AI å·¥å…·èµ„è®¯ï¼Œå¹¶è¿›è¡Œä¸ªæ€§åŒ–æ¨è
        æ”¯æŒå¤š API Key è½®è¯¢
        refresh_seed: ç”¨äºç”Ÿæˆä¸åŒæœç´¢æŸ¥è¯¢ï¼Œé¿å…ç»“æœé‡å¤
        """
        import uuid
        import asyncio
        import random
        from tavily import TavilyClient

        if not self.tavily_rotator.has_keys():
            raise Exception("æœªé…ç½® Tavily API Key")
        
        # è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ API Key
        api_key = self.tavily_rotator.get_next_key()
        print(f"ğŸ” [Tools] ä½¿ç”¨ Tavily Key: {api_key[:12]}...")
        
        # å¤šæ ·åŒ–æœç´¢å…³é”®è¯ï¼ˆä¼˜å…ˆä¸­æ–‡ï¼‰
        query_templates = [
            f"{profession} AIå·¥å…·æ¨è æé«˜æ•ˆç‡ 2024",
            f"é€‚åˆ{profession}çš„AIå·¥å…· å¿…å¤‡ç¥å™¨",
            f"{profession} å¦‚ä½•ç”¨AIå·¥å…·æå‡å·¥ä½œæ•ˆç‡",
            f"AIå·¥å…·æ¨è {profession} å®ç”¨",
            f"{profession} AIåŠå…¬å·¥å…· æœ€æ–°",
            f"å›½å†…å¥½ç”¨çš„AIå·¥å…· {profession}",
            f"{profession} AIææ•ˆå·¥å…·æ•´ç†",
        ]
        
        # ä¸­æ–‡ç½‘ç«™åŸŸåç™½åå•
        cn_domains = [
            "zhihu.com", "36kr.com", "sspai.com", "juejin.cn",
            "weixin.qq.com", "mp.weixin.qq.com", "bilibili.com",
            "csdn.net", "jianshu.com", "woshipm.com", "pmcaff.com",
            "toolify.ai", "aihub.cn", "aigc.cn"
        ]
        
        # æ ¹æ® seed é€‰æ‹©ä¸åŒçš„æŸ¥è¯¢
        query = query_templates[refresh_seed % len(query_templates)]
        print(f"   æœç´¢æŸ¥è¯¢: {query}")
        
        try:
            client = TavilyClient(api_key=api_key)
            
            response = await asyncio.to_thread(
                client.search,
                query=query,
                search_depth="basic",
                max_results=20,  # æœ€å¤§æœç´¢ç»“æœæ•°
                include_domains=cn_domains  # é™åˆ¶ä¸­æ–‡ç½‘ç«™
            )
            
            # æ ¼å¼åŒ–æœç´¢ç»“æœä¾› AI é˜…è¯»
            search_context = ""
            for i, res in enumerate(response.get("results", [])):
                search_context += f"[{i+1}] æ ‡é¢˜: {res.get('title', '')}\né“¾æ¥: {res.get('url', '')}\næ‘˜è¦: {res.get('content', '')}\n\n"
            
            if not search_context:
                raise Exception("æœªæœç´¢åˆ°æœ‰æ•ˆç»“æœ")

            # 3. AI åˆ†æä¸æå–
            prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ AI å·¥å…·åˆ†æå¸ˆã€‚æˆ‘ä¸ºä½ æœé›†äº†ä¸€äº›å…³äº"{profession}"çš„ AI å·¥å…·æœç´¢ç»“æœã€‚
è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹æœç´¢æ‘˜è¦ï¼Œå¹¶ä»ä¸­æå–æ•´ç†å‡º {result_count} ä¸ªæœ€é€‚åˆè¯¥èŒä¸šçš„çœŸå® AI å·¥å…·ã€‚

æœç´¢ç»“æœæ•°æ®ï¼š
{search_context}

è¦æ±‚ï¼š
1. **å¿…é¡»**åŸºäºä¸Šè¿°æœç´¢ç»“æœæ¨èï¼Œä¸è¦çç¼–ã€‚
2. å¦‚æœæœç´¢ç»“æœä¸­æ²¡æœ‰è¶³å¤Ÿä¿¡æ¯ï¼Œå¯ä»¥è¡¥å……ä½ å·²çŸ¥çš„ç¡®å®å­˜åœ¨çš„çŸ¥åå·¥å…·ï¼ˆå¦‚ ChatGPT, Claude, Midjourney ç­‰ï¼‰ï¼Œä½†å¿…é¡»é€‚åˆè¯¥èŒä¸šã€‚
3. é‡ç‚¹å…³æ³¨èƒ½æå‡è¯¥èŒä¸šå·¥ä½œæ•ˆç‡çš„å·¥å…·ã€‚
4. ç¡®ä¿æä¾›çœŸå®çš„å®˜ç½‘é“¾æ¥ï¼ˆå¦‚æœæœç´¢ç»“æœä¸­æœ‰ï¼Œå°±ç”¨æœç´¢ç»“æœçš„ï¼›å¦‚æœæ²¡æœ‰ï¼Œè¯·æ ¹æ®ä½ çš„çŸ¥è¯†åº“è¡¥å…¨å‡†ç¡®çš„å®˜ç½‘é“¾æ¥ï¼‰ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›ï¼š
[
  {{
    "id": "tool-1",
    "title": "å·¥å…·åç§°",
    "summary": "ç®€è¦ä»‹ç»è¯¥å·¥å…·å¯¹{profession}çš„å…·ä½“ä»·å€¼å’Œç”¨æ³•ï¼ˆ50å­—ä»¥å†…ï¼‰",
    "url": "å·¥å…·å®˜ç½‘é“¾æ¥",
    "source_name": "æ¥æºï¼ˆå¦‚ï¼šå®˜æ–¹ç½‘ç«™ã€ProductHuntã€çŸ¥ä¹ç­‰ï¼‰",
    "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2"]
  }}
]

åªè¿”å› JSON æ•°ç»„ã€‚"""

            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content.strip()
            # å°è¯•æå– JSON éƒ¨åˆ†
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            # æœ‰æ—¶å€™ AI ä¼šè¿”å› [json] ä¹‹å¤–çš„æ–‡å­—ï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª [ å’Œæœ€åä¸€ä¸ª ]
            start = content.find('[')
            end = content.rfind(']')
            if start != -1 and end != -1:
                content = content[start:end+1]

            tools = json.loads(content)
            # æ·»åŠ å”¯ä¸€ ID
            for tool in tools:
                tool['id'] = f"tool-{uuid.uuid4().hex[:8]}"
            
            return tools

        except ImportError as e:
            print(f"âŒ [Tools] ç¼ºå°‘ä¾èµ–åŒ…: {e}")
            print("   è¯·è¿è¡Œ: pip install tavily-python")
            raise e
        except Exception as e:
            error_msg = str(e).lower()
            if "api key" in error_msg or "unauthorized" in error_msg or "401" in error_msg:
                print(f"ğŸ”‘ [Tools] API Key æ— æ•ˆæˆ–å·²ç”¨å°½: {e}")
            elif "rate" in error_msg or "limit" in error_msg:
                print(f"â±ï¸ [Tools] è¾¾åˆ°é€Ÿç‡é™åˆ¶: {e}")
            else:
                print(f"âš ï¸ [Tools] æœç´¢å‡ºé”™: {e}")
            raise e

    async def search_and_recommend_cases(self, profession: str, refresh_seed: int = 0, result_count: int = 6) -> list:
        """
        ä½¿ç”¨ Tavily æœç´¢çœŸå® AI å®æˆ˜æ¡ˆä¾‹
        æ”¯æŒå¤š API Key è½®è¯¢
        refresh_seed: ç”¨äºç”Ÿæˆä¸åŒæœç´¢æŸ¥è¯¢ï¼Œé¿å…ç»“æœé‡å¤
        """
        import uuid
        import asyncio
        import random
        from tavily import TavilyClient

        if not self.tavily_rotator.has_keys():
            raise Exception("æœªé…ç½® Tavily API Key")
        
        # è·å–ä¸‹ä¸€ä¸ªå¯ç”¨çš„ API Key
        api_key = self.tavily_rotator.get_next_key()
        print(f"ğŸ” [Cases] ä½¿ç”¨ Tavily Key: {api_key[:12]}...")
        
        # å¤šæ ·åŒ–æœç´¢å…³é”®è¯ï¼ˆä¼˜å…ˆä¸­æ–‡ï¼‰
        query_templates = [
            f"{profession} AIåº”ç”¨å®æˆ˜æ¡ˆä¾‹ 2024",
            f"{profession} å¦‚ä½•ç”¨AIæé«˜æ•ˆç‡ æ¡ˆä¾‹åˆ†äº«",
            f"AIåœ¨{profession}é¢†åŸŸçš„åº”ç”¨ æˆåŠŸæ¡ˆä¾‹",
            f"{profession} AIå®è·µç»éªŒ å·¥ä½œæµ",
            f"{profession} ç”¨AIåšäº†ä»€ä¹ˆ æ•ˆæœ",
            f"AIåŠ©åŠ›{profession} å®é™…æ¡ˆä¾‹",
            f"{profession} AIè‡ªåŠ¨åŒ– å®æˆ˜åˆ†äº«",
        ]
        
        # ä¸­æ–‡ç½‘ç«™åŸŸåç™½åå•
        cn_domains = [
            "zhihu.com", "36kr.com", "sspai.com", "juejin.cn",
            "weixin.qq.com", "mp.weixin.qq.com", "bilibili.com",
            "csdn.net", "jianshu.com", "woshipm.com", "pmcaff.com",
            "toolify.ai", "aihub.cn", "aigc.cn"
        ]
        
        # æ ¹æ® seed é€‰æ‹©ä¸åŒçš„æŸ¥è¯¢
        query = query_templates[refresh_seed % len(query_templates)]
        print(f"   æœç´¢æŸ¥è¯¢: {query}")
        
        try:
            client = TavilyClient(api_key=api_key)
            
            response = await asyncio.to_thread(
                client.search,
                query=query,
                search_depth="basic",
                max_results=20,  # æœ€å¤§æœç´¢ç»“æœæ•°
                include_domains=cn_domains  # é™åˆ¶ä¸­æ–‡ç½‘ç«™
            )
            
            search_context = ""
            for i, res in enumerate(response.get("results", [])):
                search_context += f"[{i+1}] æ ‡é¢˜: {res.get('title', '')}\né“¾æ¥: {res.get('url', '')}\næ‘˜è¦: {res.get('content', '')}\n\n"
            
            if not search_context:
                raise Exception("æœªæœç´¢åˆ°æœ‰æ•ˆç»“æœ")

            # 3. AI åˆ†æä¸æå–
            prompt = f"""ä½ æ˜¯ä¸€ä½ AI åº”ç”¨ä¸“å®¶ã€‚æˆ‘ä¸ºä½ æœé›†äº†ä¸€äº›"{profession}"ä½¿ç”¨ AI çš„ç›¸å…³æœç´¢ç»“æœã€‚
è¯·ä»è¿™äº›ç»“æœä¸­æç‚¼å‡º {result_count} ä¸ªå…·ä½“çš„å®æˆ˜æ¡ˆä¾‹æˆ–åº”ç”¨åœºæ™¯ã€‚

æœç´¢ç»“æœæ•°æ®ï¼š
{search_context}

è¦æ±‚ï¼š
1. æ¡ˆä¾‹å¿…é¡»çœŸå®ã€å…·ä½“ï¼Œæœ€å¥½æœ‰å…·ä½“çš„åº”ç”¨åœºæ™¯æè¿°ã€‚
2. å¦‚æœæœç´¢ç»“æœä¸»è¦æ˜¯å·¥å…·ä»‹ç»ï¼Œè¯·ä½ æ ¹æ®è¯¥å·¥å…·æ¨å¯¼å‡ºé€‚åˆè¯¥èŒä¸šçš„å…¸å‹åº”ç”¨åœºæ™¯ï¼ˆæ ‡æ³¨ä¸º"åº”ç”¨å»ºè®®"ï¼‰ã€‚
3. é‡ç‚¹å±•ç¤º AI å¦‚ä½•é™æœ¬å¢æ•ˆã€‚
4. é“¾æ¥è¯·ä½¿ç”¨æœç´¢ç»“æœä¸­çš„åŸå§‹é“¾æ¥ã€‚

è¯·ä¸¥æ ¼æŒ‰ç…§ JSON æ ¼å¼è¿”å›ï¼š
[
  {{
    "id": "case-1",
    "title": "æ¡ˆä¾‹æ ‡é¢˜ï¼ˆå¦‚ï¼šç”¨ ChatGPT è‡ªåŠ¨ç”Ÿæˆå‘¨æŠ¥ï¼‰",
    "summary": "æ¡ˆä¾‹ç®€ä»‹ï¼šè§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Œç”¨äº†ä»€ä¹ˆæ–¹æ³•ï¼Œè¾¾åˆ°äº†ä»€ä¹ˆæ•ˆæœï¼ˆ80å­—ä»¥å†…ï¼‰",
    "url": "ç›¸å…³æ–‡ç« æˆ–æ¥æºé“¾æ¥",
    "source_name": "æ¥æºï¼ˆå¦‚ï¼šMediumã€çŸ¥ä¹ã€è¡Œä¸šåšå®¢ç­‰ï¼‰",
    "tags": ["#æ ‡ç­¾1", "#æ ‡ç­¾2"]
  }}
]

åªè¿”å› JSON æ•°ç»„ã€‚"""

            response = await asyncio.to_thread(
                self.client.chat.completions.create,
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=2000
            )
            
            content = response.choices[0].message.content.strip()
            # å°è¯•æå– JSON éƒ¨åˆ†
            if "```json" in content:
                content = content.split("```json")[1].split("```")[0].strip()
            elif "```" in content:
                content = content.split("```")[1].strip()
            
            # æœ‰æ—¶å€™ AI ä¼šè¿”å› [json] ä¹‹å¤–çš„æ–‡å­—ï¼Œå°è¯•æ‰¾åˆ°ç¬¬ä¸€ä¸ª [ å’Œæœ€åä¸€ä¸ª ]
            start = content.find('[')
            end = content.rfind(']')
            if start != -1 and end != -1:
                content = content[start:end+1]
            
            cases = json.loads(content)
            for case in cases:
                case['id'] = f"case-{uuid.uuid4().hex[:8]}"
            
            return cases

        except ImportError as e:
            print(f"âŒ [Cases] ç¼ºå°‘ä¾èµ–åŒ…: {e}")
            print("   è¯·è¿è¡Œ: pip install tavily-python")
            raise e
        except Exception as e:
            error_msg = str(e).lower()
            if "api key" in error_msg or "unauthorized" in error_msg or "401" in error_msg:
                print(f"ğŸ”‘ [Cases] API Key æ— æ•ˆæˆ–å·²ç”¨å°½: {e}")
            elif "rate" in error_msg or "limit" in error_msg:
                print(f"â±ï¸ [Cases] è¾¾åˆ°é€Ÿç‡é™åˆ¶: {e}")
            else:
                print(f"âš ï¸ [Cases] æœç´¢å‡ºé”™: {e}")
            raise e

    async def _search_web(self, query: str) -> str:
        """ä¿ç•™æ­¤è¾…åŠ©æ–¹æ³•ä½†æš‚æ—¶ä¸ç”¨"""
        return ""


# Global processor instance
ai_processor = AIProcessor()
